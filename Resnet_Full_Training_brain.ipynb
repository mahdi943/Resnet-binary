{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahdi943/Resnet-tumor-classifier/blob/master/Resnet_Full_Training_brain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "k_uBeZBxiUbO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io\n",
        "from numpy import random\n",
        "\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, BatchNormalization,Activation, Flatten, GlobalAveragePooling2D, SeparableConv2D\n",
        "from keras.models import Model\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import metrics\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.layers import Dropout\n",
        "from keras.regularizers import l2\n",
        "from keras.regularizers import l1\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import cv2\n",
        "import os\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from PIL import Image\n",
        "np.random.seed(5)\n",
        "from keras.preprocessing.image import load_img,img_to_array,array_to_img,save_img"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_K4N35WCkc2j",
        "outputId": "d98b03bd-cec5-4897-bb80-8dbc7878fed3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKqiU33HZuOR"
      },
      "outputs": [],
      "source": [
        "!unzip \"/content/drive/MyDrive/Colab Notebooks/CS515 - project/dataset/dataset/Train.zip\"\n",
        "!unzip \"/content/drive/MyDrive/Colab Notebooks/CS515 - project/dataset/dataset/Test.zip\"\n",
        "!unzip \"/content/drive/MyDrive/Colab Notebooks/CS515 - project/dataset/dataset/Valid.zip\"\n",
        "\n",
        "y_col = ['Class0', 'Class1']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.resnet import ResNet152\n",
        "from keras.applications.vgg16 import VGG16\n",
        "\n",
        "base_model = ResNet152(weights = 'imagenet', include_top = False, input_shape=(500, 500, 3))\n",
        "\n",
        "base_model.layers.pop()\n",
        "base_model.layers.pop()\n",
        "base_model.layers.pop()\n",
        "base_model.layers.pop()\n",
        "\n",
        "last_few_layers = 4\n",
        "# for layer in base_model.layers[:-last_few_layers]:\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# base_model.summary()"
      ],
      "metadata": {
        "id": "HLp-guc6dZOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "F4KvPonulG7_"
      },
      "outputs": [],
      "source": [
        "def brain_model(base_model, img_shape = (500,500,3)):\n",
        "    \n",
        "    # create the input layer (Same as the imageNetv2 input size)\n",
        "    inputs = tf.keras.Input(shape=img_shape) \n",
        "    \n",
        "    # Forward pass to get the output of the last pooling layer\n",
        "    X = base_model(inputs)\n",
        "    X = GlobalAveragePooling2D()(X)\n",
        "    X = Dropout(.25)(X)\n",
        "\n",
        "    # Define the new binary classification head \n",
        "    X = Dense(1024, activation='relu', name='fc1')(X)\n",
        "    X = Dropout(.5)(X)\n",
        "    X = Dense(512, activation='relu', name='fc2')(X)\n",
        "    X = Dropout(.5)(X)\n",
        "    X = Dense(256, activation='relu', name='fc3')(X)\n",
        "    X = Dropout(.5)(X)\n",
        "    X = Dense(128, activation='relu', name='fc4')(X)\n",
        "    X = Dropout(.5)(X)\n",
        "    X = Dense(64, activation='relu', name='fc5')(X)\n",
        "    X = Dropout(.5)(X)\n",
        "        \n",
        "    outputs = Dense(2,activation='softmax', name='Predictions')(X)\n",
        "    model = tf.keras.Model(inputs, outputs)\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "XYzQ87QARfam",
        "outputId": "cb32c753-5dc3-47cd-8885-7609d5a0f56f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 256 validated image filenames.\n",
            "Found 64 validated image filenames.\n",
            "Epoch 1/20\n",
            "16/16 [==============================] - 34s 2s/step - loss: 1.6277 - accuracy: 0.5820 - val_loss: 0.7414 - val_accuracy: 0.7500\n",
            "Epoch 2/20\n",
            "16/16 [==============================] - 24s 1s/step - loss: 1.3547 - accuracy: 0.6406 - val_loss: 0.5619 - val_accuracy: 0.7500\n",
            "Epoch 3/20\n",
            "16/16 [==============================] - 23s 1s/step - loss: 1.1653 - accuracy: 0.6172 - val_loss: 0.5602 - val_accuracy: 0.7500\n",
            "Epoch 4/20\n",
            "16/16 [==============================] - 23s 1s/step - loss: 0.9362 - accuracy: 0.6250 - val_loss: 0.5799 - val_accuracy: 0.7500\n",
            "Epoch 5/20\n",
            "16/16 [==============================] - 22s 1s/step - loss: 0.8737 - accuracy: 0.6250 - val_loss: 0.5959 - val_accuracy: 0.7500\n",
            "Epoch 6/20\n",
            "16/16 [==============================] - 22s 1s/step - loss: 0.7596 - accuracy: 0.6484 - val_loss: 0.5910 - val_accuracy: 0.7500\n",
            "Epoch 7/20\n",
            "16/16 [==============================] - 22s 1s/step - loss: 0.7511 - accuracy: 0.6367 - val_loss: 0.5917 - val_accuracy: 0.7500\n",
            "Epoch 8/20\n",
            "16/16 [==============================] - 23s 1s/step - loss: 0.7685 - accuracy: 0.6562 - val_loss: 0.6113 - val_accuracy: 0.7500\n",
            "Epoch 9/20\n",
            "16/16 [==============================] - 22s 1s/step - loss: 0.6768 - accuracy: 0.6680 - val_loss: 0.6228 - val_accuracy: 0.7500\n",
            "Epoch 10/20\n",
            "16/16 [==============================] - 23s 1s/step - loss: 0.6805 - accuracy: 0.6641 - val_loss: 0.6210 - val_accuracy: 0.7500\n",
            "Epoch 11/20\n",
            "16/16 [==============================] - 22s 1s/step - loss: 0.6424 - accuracy: 0.6992 - val_loss: 0.6114 - val_accuracy: 0.7500\n",
            "Epoch 12/20\n",
            "16/16 [==============================] - 22s 1s/step - loss: 0.6480 - accuracy: 0.6875 - val_loss: 0.6073 - val_accuracy: 0.7500\n",
            "Epoch 13/20\n",
            "16/16 [==============================] - 22s 1s/step - loss: 0.6670 - accuracy: 0.6914 - val_loss: 0.6082 - val_accuracy: 0.7500\n",
            "Epoch 14/20\n",
            "16/16 [==============================] - 22s 1s/step - loss: 0.6206 - accuracy: 0.7188 - val_loss: 0.5967 - val_accuracy: 0.7500\n",
            "Epoch 15/20\n",
            "16/16 [==============================] - 23s 1s/step - loss: 0.6324 - accuracy: 0.7188 - val_loss: 0.6324 - val_accuracy: 0.7500\n",
            "Epoch 16/20\n",
            "16/16 [==============================] - 23s 1s/step - loss: 0.6346 - accuracy: 0.7266 - val_loss: 0.6111 - val_accuracy: 0.7500\n",
            "Epoch 17/20\n",
            "16/16 [==============================] - 22s 1s/step - loss: 0.6293 - accuracy: 0.7031 - val_loss: 0.6145 - val_accuracy: 0.7500\n",
            "Epoch 18/20\n",
            "16/16 [==============================] - 22s 1s/step - loss: 0.6297 - accuracy: 0.7031 - val_loss: 0.6234 - val_accuracy: 0.7500\n",
            "Epoch 19/20\n",
            "16/16 [==============================] - 22s 1s/step - loss: 0.5976 - accuracy: 0.7305 - val_loss: 0.6173 - val_accuracy: 0.7500\n",
            "Epoch 20/20\n",
            "16/16 [==============================] - 22s 1s/step - loss: 0.6008 - accuracy: 0.7539 - val_loss: 0.6224 - val_accuracy: 0.7500\n",
            "\n",
            "Test generator:\n",
            "\n",
            "Found 80 validated image filenames.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.75"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "model1 = brain_model (base_model, img_shape = (500,500,3))\n",
        "\n",
        "\n",
        "dataclass1 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/CS515 - project/dataset/dataset/labelTrain1.csv') \n",
        "data1class1 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/CS515 - project/dataset/dataset/labelValid1.csv')\n",
        "data2class1 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/CS515 - project/dataset/dataset/labelTest1.csv')\n",
        "data3class1 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/CS515 - project/dataset/dataset/labelTestfinal.csv')\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "data_path = \"/content/Train\" \n",
        "\n",
        "dataclass1 = dataclass1.sample(frac=1)\n",
        "dataclass1.reset_index(drop = True, inplace = True)\n",
        "\n",
        "train_aug = ImageDataGenerator(\trescale=1/255.0,\t\n",
        "                              #  width_shift_range=[-100,100], \n",
        "                              #  height_shift_range=0.5,       \n",
        "                               shear_range=0.2,\n",
        "                               horizontal_flip=True,\n",
        "                               vertical_flip=True,\n",
        "                               rotation_range=90,\n",
        "                               brightness_range=[0.2,0.05],\n",
        "                               zoom_range=0.2\n",
        "                               )\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_aug = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_aug.flow_from_dataframe(\n",
        "    dataframe=dataclass1,\n",
        "    directory=data_path,\n",
        "    x_col='Image',\n",
        "    y_col= y_col,\n",
        "    class_mode=\"raw\",\n",
        "    shuffle=True,\n",
        "    target_size=(500,500), \n",
        "    batch_size=batch_size)\n",
        "\n",
        "valid_generator = test_aug.flow_from_dataframe(\n",
        "    dataframe=data1class1,\n",
        "    directory=\"/content/Valid\",\n",
        "    x_col='Image',\n",
        "    y_col= y_col,\n",
        "    class_mode= \"raw\",\n",
        "    target_size=(500,500),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
        "# optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "model1.compile(optimizer='nadam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model1.fit(train_generator, batch_size= 16 ,epochs=20, validation_data = valid_generator, callbacks= callback)\n",
        "\n",
        "print('\\nTest generator:\\n')\n",
        "\n",
        "test_generator1 = test_aug.flow_from_dataframe(\n",
        "    dataframe=data2class1,\n",
        "    directory=\"/content/Test\",\n",
        "    x_col='Image',\n",
        "    y_col= y_col,\n",
        "    shuffle=True,\n",
        "    class_mode= \"raw\",\n",
        "    target_size=(500,500),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "y_predict = model1.predict(test_generator1)\n",
        "y_predict = y_predict.argmax(-1)\n",
        "accuracy_score(data3class1['label'],y_predict)\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = brain_model (base_model, img_shape = (500,500,3))\n",
        "\n",
        "dataclass2 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/CS515 - project/dataset/dataset-class2/labelTrain-class2.csv') \n",
        "data1class2 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/CS515 - project/dataset/dataset-class2/labelValid-class2.csv')\n",
        "data2class2 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/CS515 - project/dataset/dataset-class2/labelTest-class2.csv')\n",
        "data3class2 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/CS515 - project/dataset/dataset-class2/labelTestfinal-class2.csv')\n",
        "\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "data_path = \"/content/Train\" \n",
        "\n",
        "#shuffle the data\n",
        "dataclass2 = dataclass2.sample(frac=1)\n",
        "dataclass2.reset_index(drop = True, inplace = True)\n",
        "\n",
        "train_aug = ImageDataGenerator(\trescale=1/255.0,\t\n",
        "                               shear_range=0.2,\n",
        "                               width_shift_range=0.1,\n",
        "                               height_shift_range=0.1,\n",
        "                               horizontal_flip=True,\n",
        "                               vertical_flip=True,\n",
        "                               rotation_range=90,\n",
        "                               brightness_range=[0.2,0.02],\n",
        "                               zoom_range=0.2,\n",
        "                               )  \n",
        "\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_aug = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_aug.flow_from_dataframe(\n",
        "    dataframe=dataclass2,\n",
        "    directory=data_path,\n",
        "    x_col='Image',\n",
        "    y_col= y_col,\n",
        "    class_mode=\"raw\",\n",
        "    shuffle=True,\n",
        "    target_size=(500,500), \n",
        "    batch_size=batch_size)\n",
        "\n",
        "valid_generator = test_aug.flow_from_dataframe(\n",
        "    dataframe=data1class2,\n",
        "    directory=\"/content/Valid\",\n",
        "    x_col='Image',\n",
        "    y_col= y_col,\n",
        "    class_mode= \"raw\",\n",
        "    target_size=(500,500),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "# from tensorflow.keras.optimizers import SGD\n",
        "# opt = SGD(learning_rate=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
        "# optimizer = tf.keras.optimizers.Adam(lr=0.001)\n",
        "model2.compile(optimizer='nadam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model2.fit(train_generator, batch_size= 16 ,epochs=25, validation_data = valid_generator, callbacks= callback)\n",
        "\n",
        "print('\\nTest generator:\\n')\n",
        "\n",
        "test_generator2 = test_aug.flow_from_dataframe(\n",
        "    dataframe=data2class2,\n",
        "    directory=\"/content/Test\",\n",
        "    x_col='Image',\n",
        "    y_col= y_col,\n",
        "    shuffle=True,\n",
        "    class_mode= \"raw\",\n",
        "    target_size=(500,500),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "y_predict = model2.predict(test_generator2)\n",
        "y_predict = y_predict.argmax(-1)\n",
        "accuracy_score(data3class2['label'],y_predict)\n",
        "    \n",
        "\n"
      ],
      "metadata": {
        "id": "IFN-KofL5eWb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0f2ce68-c127-4e63-dbe9-cbcad85bd909"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 256 validated image filenames.\n",
            "Found 64 validated image filenames.\n",
            "Epoch 1/25\n",
            "16/16 [==============================] - 33s 2s/step - loss: 2.0665 - accuracy: 0.5586 - val_loss: 0.8189 - val_accuracy: 0.7500\n",
            "Epoch 2/25\n",
            "16/16 [==============================] - 22s 1s/step - loss: 1.7778 - accuracy: 0.5938 - val_loss: 0.6380 - val_accuracy: 0.7500\n",
            "Epoch 3/25\n",
            "16/16 [==============================] - 22s 1s/step - loss: 1.3122 - accuracy: 0.6055 - val_loss: 0.5655 - val_accuracy: 0.7500\n",
            "Epoch 4/25\n",
            "16/16 [==============================] - 22s 1s/step - loss: 1.0645 - accuracy: 0.6172 - val_loss: 0.5664 - val_accuracy: 0.7500\n",
            "Epoch 5/25\n",
            "16/16 [==============================] - 24s 1s/step - loss: 0.9631 - accuracy: 0.6172 - val_loss: 0.6260 - val_accuracy: 0.7500\n",
            "Epoch 6/25\n",
            "16/16 [==============================] - 23s 1s/step - loss: 0.7694 - accuracy: 0.6406 - val_loss: 0.6084 - val_accuracy: 0.7500\n",
            "Epoch 7/25\n",
            "16/16 [==============================] - 23s 1s/step - loss: 0.7168 - accuracy: 0.7188 - val_loss: 0.6495 - val_accuracy: 0.7500\n",
            "Epoch 8/25\n",
            "16/16 [==============================] - 23s 1s/step - loss: 0.6734 - accuracy: 0.6602 - val_loss: 0.6206 - val_accuracy: 0.7500\n",
            "Epoch 9/25\n",
            "16/16 [==============================] - 23s 1s/step - loss: 0.7352 - accuracy: 0.6602 - val_loss: 0.5950 - val_accuracy: 0.7500\n",
            "Epoch 10/25\n",
            "16/16 [==============================] - 23s 1s/step - loss: 0.6714 - accuracy: 0.6914 - val_loss: 0.6139 - val_accuracy: 0.7500\n",
            "Epoch 11/25\n",
            "16/16 [==============================] - 23s 1s/step - loss: 0.6932 - accuracy: 0.6602 - val_loss: 0.6180 - val_accuracy: 0.7500\n",
            "Epoch 12/25\n",
            "16/16 [==============================] - 23s 1s/step - loss: 0.6613 - accuracy: 0.6719 - val_loss: 0.6225 - val_accuracy: 0.7500\n",
            "Epoch 13/25\n",
            "16/16 [==============================] - 23s 1s/step - loss: 0.6104 - accuracy: 0.7070 - val_loss: 0.5885 - val_accuracy: 0.7500\n",
            "Epoch 14/25\n",
            "16/16 [==============================] - 23s 1s/step - loss: 0.6387 - accuracy: 0.7031 - val_loss: 0.5941 - val_accuracy: 0.7500\n",
            "Epoch 15/25\n",
            "16/16 [==============================] - 23s 1s/step - loss: 0.6655 - accuracy: 0.6953 - val_loss: 0.6134 - val_accuracy: 0.7500\n",
            "Epoch 16/25\n",
            "16/16 [==============================] - 23s 1s/step - loss: 0.6289 - accuracy: 0.7188 - val_loss: 0.6154 - val_accuracy: 0.7500\n",
            "Epoch 17/25\n",
            "16/16 [==============================] - 23s 1s/step - loss: 0.6199 - accuracy: 0.7344 - val_loss: 0.6047 - val_accuracy: 0.7500\n",
            "Epoch 18/25\n",
            "16/16 [==============================] - 23s 1s/step - loss: 0.6364 - accuracy: 0.7031 - val_loss: 0.6188 - val_accuracy: 0.7500\n",
            "\n",
            "Test generator:\n",
            "\n",
            "Found 80 validated image filenames.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.75"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = brain_model (base_model, img_shape = (500,500,3))\n",
        "\n",
        "dataclass3 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/CS515 - project/dataset/dataset-class3/labelTrain-class3.csv') \n",
        "data1class3 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/CS515 - project/dataset/dataset-class3/labelValid-class3.csv')\n",
        "data2class3 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/CS515 - project/dataset/dataset-class3/labelTest-class3.csv')\n",
        "data3class3 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/CS515 - project/dataset/dataset-class3/labelTestfinal-class3.csv')\n",
        "dataTestFinal = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/CS515 - project/dataset/dataset/test_brain.csv')\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "data_path = \"/content/Train\" \n",
        "\n",
        "#shuffle the data\n",
        "dataclass3 = dataclass3.sample(frac=1)\n",
        "dataclass3.reset_index(drop = True, inplace = True)\n",
        "\n",
        "train_aug = ImageDataGenerator(\trescale=1/255.0,\t     \n",
        "                               shear_range=0.2,\n",
        "                               width_shift_range=0.1,\n",
        "                               height_shift_range=0.1,\n",
        "                               horizontal_flip=True,\n",
        "                               vertical_flip=True,\n",
        "                               rotation_range=90,\n",
        "                               brightness_range=[0.2,0.02],\n",
        "                               zoom_range=0.2,\n",
        "                               )                               \n",
        "                              #  rotation_range=20,\t\n",
        "                              #  zoom_range=0.05,\t\n",
        "                              #  width_shift_range=0.1,\t\n",
        "                              #  height_shift_range=0.1,\t\n",
        "                              #  shear_range=0.05,\t\n",
        "                              #  horizontal_flip=True,\t\n",
        "                              #  vertical_flip=True,\t\n",
        "                              #  fill_mode=\"nearest\"\n",
        "                              #  )\n",
        "\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_aug = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_aug.flow_from_dataframe(\n",
        "    dataframe=dataclass3,\n",
        "    directory=data_path,\n",
        "    x_col='Image',\n",
        "    y_col= y_col,\n",
        "    class_mode=\"raw\",\n",
        "    shuffle=True,\n",
        "    target_size=(500,500), \n",
        "    batch_size=batch_size)\n",
        "\n",
        "valid_generator = test_aug.flow_from_dataframe(\n",
        "    dataframe=data1class3,\n",
        "    directory=\"/content/Valid\",\n",
        "    x_col='Image',\n",
        "    y_col= y_col,\n",
        "    class_mode= \"raw\",\n",
        "    target_size=(500,500),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "# opt = SGD(learning_rate=1e-3, decay=1e-6, momentum=0.8, nesterov=True)\n",
        "\n",
        "model3.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model3.fit(train_generator, batch_size= 32, epochs=25, validation_data = valid_generator, callbacks= callback)\n",
        "\n",
        "\n",
        "print('test generator:\\n')\n",
        "test_generator3 = test_aug.flow_from_dataframe(\n",
        "    dataframe=data2class3,\n",
        "    directory=\"/content/Test\",\n",
        "    x_col='Image',\n",
        "    y_col= y_col,\n",
        "    shuffle=True,\n",
        "    class_mode= \"raw\",\n",
        "    target_size=(500,500),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "y_predict = model3.predict(test_generator3)\n",
        "y_predict = y_predict.argmax(-1)\n",
        "accuracy_score(data3class3['label'],y_predict)\n",
        "    \n",
        "\n"
      ],
      "metadata": {
        "id": "ynDxuA9r5w5P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ab42b92-6b36-4c79-e370-356bd18f0560"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 256 validated image filenames.\n",
            "Found 64 validated image filenames.\n",
            "Epoch 1/25\n",
            "16/16 [==============================] - 52s 2s/step - loss: 1.6336 - accuracy: 0.6172 - val_loss: 0.5800 - val_accuracy: 0.7500\n",
            "Epoch 2/25\n",
            "16/16 [==============================] - 23s 1s/step - loss: 1.6977 - accuracy: 0.6484 - val_loss: 0.5771 - val_accuracy: 0.7500\n",
            "Epoch 3/25\n",
            "16/16 [==============================] - 24s 1s/step - loss: 1.4247 - accuracy: 0.5664 - val_loss: 0.6652 - val_accuracy: 0.7500\n",
            "Epoch 4/25\n",
            "16/16 [==============================] - 23s 1s/step - loss: 1.0616 - accuracy: 0.6445 - val_loss: 0.6134 - val_accuracy: 0.7500\n",
            "Epoch 5/25\n",
            "16/16 [==============================] - 23s 1s/step - loss: 0.8864 - accuracy: 0.6602 - val_loss: 0.6805 - val_accuracy: 0.7500\n",
            "Epoch 6/25\n",
            "16/16 [==============================] - 23s 1s/step - loss: 0.8539 - accuracy: 0.6367 - val_loss: 0.6315 - val_accuracy: 0.7500\n",
            "Epoch 7/25\n",
            "16/16 [==============================] - 23s 1s/step - loss: 0.7956 - accuracy: 0.6250 - val_loss: 0.6367 - val_accuracy: 0.7500\n",
            "Epoch 8/25\n",
            "16/16 [==============================] - 23s 1s/step - loss: 0.7013 - accuracy: 0.6406 - val_loss: 0.6511 - val_accuracy: 0.7500\n",
            "Epoch 9/25\n",
            "16/16 [==============================] - 23s 1s/step - loss: 0.6698 - accuracy: 0.6523 - val_loss: 0.6424 - val_accuracy: 0.7500\n",
            "Epoch 10/25\n",
            "16/16 [==============================] - 22s 1s/step - loss: 0.6261 - accuracy: 0.6836 - val_loss: 0.6135 - val_accuracy: 0.7500\n",
            "Epoch 11/25\n",
            "16/16 [==============================] - 23s 1s/step - loss: 0.6672 - accuracy: 0.6992 - val_loss: 0.6346 - val_accuracy: 0.7500\n",
            "Epoch 12/25\n",
            "16/16 [==============================] - 22s 1s/step - loss: 0.6269 - accuracy: 0.6914 - val_loss: 0.6261 - val_accuracy: 0.7500\n",
            "Epoch 13/25\n",
            "16/16 [==============================] - 22s 1s/step - loss: 0.6158 - accuracy: 0.6875 - val_loss: 0.6170 - val_accuracy: 0.7500\n",
            "Epoch 14/25\n",
            "16/16 [==============================] - 22s 1s/step - loss: 0.6063 - accuracy: 0.7070 - val_loss: 0.6152 - val_accuracy: 0.7500\n",
            "Epoch 15/25\n",
            "16/16 [==============================] - 22s 1s/step - loss: 0.6250 - accuracy: 0.7148 - val_loss: 0.6161 - val_accuracy: 0.7500\n",
            "Epoch 16/25\n",
            "16/16 [==============================] - 22s 1s/step - loss: 0.6133 - accuracy: 0.7305 - val_loss: 0.6051 - val_accuracy: 0.7500\n",
            "Epoch 17/25\n",
            "16/16 [==============================] - 22s 1s/step - loss: 0.5901 - accuracy: 0.7305 - val_loss: 0.6202 - val_accuracy: 0.7500\n",
            "Epoch 18/25\n",
            "16/16 [==============================] - 22s 1s/step - loss: 0.6210 - accuracy: 0.6914 - val_loss: 0.6110 - val_accuracy: 0.7500\n",
            "Epoch 19/25\n",
            "16/16 [==============================] - 22s 1s/step - loss: 0.5775 - accuracy: 0.7461 - val_loss: 0.5960 - val_accuracy: 0.7500\n",
            "Epoch 20/25\n",
            "16/16 [==============================] - 22s 1s/step - loss: 0.6280 - accuracy: 0.7383 - val_loss: 0.6094 - val_accuracy: 0.7500\n",
            "Epoch 21/25\n",
            "16/16 [==============================] - 22s 1s/step - loss: 0.6175 - accuracy: 0.7227 - val_loss: 0.6275 - val_accuracy: 0.7500\n",
            "Epoch 22/25\n",
            "16/16 [==============================] - 25s 2s/step - loss: 0.5972 - accuracy: 0.7461 - val_loss: 0.6198 - val_accuracy: 0.7500\n",
            "Epoch 23/25\n",
            "16/16 [==============================] - 22s 1s/step - loss: 0.5874 - accuracy: 0.7461 - val_loss: 0.6001 - val_accuracy: 0.7500\n",
            "Epoch 24/25\n",
            "16/16 [==============================] - 22s 1s/step - loss: 0.6407 - accuracy: 0.7227 - val_loss: 0.6184 - val_accuracy: 0.7500\n",
            "test generator:\n",
            "\n",
            "Found 80 validated image filenames.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.75"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model4 = brain_model (base_model, img_shape = (500,500,3))\n",
        "\n",
        "dataclass4 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/CS515 - project/dataset/dataset-class4/labelTrain-class4.csv') \n",
        "data1class4 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/CS515 - project/dataset/dataset-class4/labelValid-class4.csv')\n",
        "data2class4 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/CS515 - project/dataset/dataset-class4/labelTest-class4.csv')\n",
        "data3class4 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/CS515 - project/dataset/dataset-class4/labelTestfinal-class4.csv')\n",
        "dataTestFinal = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/CS515 - project/dataset/dataset/test_brain.csv')\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "data_path = \"/content/Train\" \n",
        "\n",
        "#shuffle the data\n",
        "dataclass4 = dataclass4.sample(frac=1)\n",
        "dataclass4.reset_index(drop = True, inplace = True)\n",
        "\n",
        "train_aug = ImageDataGenerator(\trescale=1/255.0,\t     \n",
        "                               shear_range=0.2,\n",
        "                               width_shift_range=0.1,\n",
        "                               height_shift_range=0.1,\n",
        "                               horizontal_flip=True,\n",
        "                               vertical_flip=True,\n",
        "                               rotation_range=90,\n",
        "                               brightness_range=[0.2,0.02],\n",
        "                               zoom_range=0.2,\n",
        "                               )                               \n",
        "                              #  rotation_range=20,\t\n",
        "                              #  zoom_range=0.05,\t\n",
        "                              #  width_shift_range=0.1,\t\n",
        "                              #  height_shift_range=0.1,\t\n",
        "                              #  shear_range=0.05,\t\n",
        "                              #  horizontal_flip=True,\t\n",
        "                              #  vertical_flip=True,\t\n",
        "                              #  fill_mode=\"nearest\"\n",
        "                              #  )\n",
        "\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_aug = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_aug.flow_from_dataframe(\n",
        "    dataframe=dataclass4,\n",
        "    directory=data_path,\n",
        "    x_col='Image',\n",
        "    y_col= y_col,\n",
        "    class_mode=\"raw\",\n",
        "    shuffle=True,\n",
        "    target_size=(500,500), \n",
        "    batch_size=batch_size)\n",
        "\n",
        "valid_generator = test_aug.flow_from_dataframe(\n",
        "    dataframe=data1class4,\n",
        "    directory=\"/content/Valid\",\n",
        "    x_col='Image',\n",
        "    y_col= y_col,\n",
        "    class_mode= \"raw\",\n",
        "    target_size=(500,500),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "# opt = SGD(learning_rate=1e-3, decay=1e-6, momentum=0.8, nesterov=True)\n",
        "\n",
        "model4.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model4.fit(train_generator, batch_size= 16, epochs=20, validation_data = valid_generator, callbacks= callback)\n",
        "\n",
        "\n",
        "print('test generator:\\n')\n",
        "test_generator4 = test_aug.flow_from_dataframe(\n",
        "    dataframe=data2class4,\n",
        "    directory=\"/content/Test\",\n",
        "    x_col='Image',\n",
        "    y_col= y_col,\n",
        "    shuffle=True,\n",
        "    class_mode= \"raw\",\n",
        "    target_size=(500,500),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "y_predict = model4.predict(test_generator3)\n",
        "y_predict = y_predict.argmax(-1)\n",
        "accuracy_score(data3class4['label'],y_predict)\n",
        "    \n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYBBGLeEDiJu",
        "outputId": "e0e3109f-f126-4697-d32b-173008233b3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 256 validated image filenames.\n",
            "Found 64 validated image filenames.\n",
            "Epoch 1/20\n",
            "16/16 [==============================] - 33s 2s/step - loss: 2.1831 - accuracy: 0.6133 - val_loss: 0.7319 - val_accuracy: 0.2500\n",
            "Epoch 2/20\n",
            "16/16 [==============================] - 22s 1s/step - loss: 1.6248 - accuracy: 0.5898 - val_loss: 0.5824 - val_accuracy: 0.7500\n",
            "Epoch 3/20\n",
            "16/16 [==============================] - 23s 1s/step - loss: 1.1125 - accuracy: 0.6680 - val_loss: 0.5829 - val_accuracy: 0.7500\n",
            "Epoch 4/20\n",
            "16/16 [==============================] - 22s 1s/step - loss: 0.9898 - accuracy: 0.6758 - val_loss: 0.5805 - val_accuracy: 0.7500\n",
            "Epoch 5/20\n",
            "16/16 [==============================] - 22s 1s/step - loss: 0.9060 - accuracy: 0.6523 - val_loss: 0.6089 - val_accuracy: 0.7500\n",
            "Epoch 6/20\n",
            " 2/16 [==>...........................] - ETA: 16s - loss: 0.6793 - accuracy: 0.6875"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict1 = model1.predict(test_generator1)\n",
        "y_predict1 = y_predict1.argmax(-1)\n",
        "\n",
        "y_predict2 = model2.predict(test_generator2)\n",
        "y_predict2 = y_predict2.argmax(-1)\n",
        "\n",
        "y_predict3 = model3.predict(test_generator3)\n",
        "y_predict3 = y_predict3.argmax(-1)\n",
        "\n",
        "y_predict4 = model4.predict(test_generator3)\n",
        "y_predict4 = y_predict4.argmax(-1)\n",
        "\n",
        "final_predict = np.zeros((79,1))\n",
        "\n",
        "for i in range(79):\n",
        "\n",
        "  if y_predict4[i] == 1:\n",
        "    final_predict[i] = 3\n",
        "  \n",
        "  elif y_predict3[i] == 1:\n",
        "    final_predict[i] = 2 \n",
        "  \n",
        "  elif y_predict2[i] == 1:\n",
        "    final_predict[i] = 1\n",
        "  \n",
        "  else:\n",
        "    final_predict[i] = 0\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FooB3vkv188K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLo9rnpzZuOU"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import metrics\n",
        "\n",
        "accuracy_score(dataTestFinal['label'],final_predict)\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmEvkNzrZuOU"
      },
      "outputs": [],
      "source": [
        "# plt.plot(history.history['loss'])\n",
        "# plt.title('model loss')\n",
        "# plt.ylabel('accuracy')\n",
        "# plt.xlabel('epoch')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2EBxm55ZuOU"
      },
      "outputs": [],
      "source": [
        "# plt.plot(history.history['accuracy'])\n",
        "# plt.title('model accuracy')\n",
        "# plt.ylabel('accuracy')\n",
        "# plt.xlabel('epoch')\n",
        "# plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Resnet-Full-Training_brain.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}